import pandas as pd 
import numpy as np
import os
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

# replace with your folder's path
folder_path = os.getcwd()

all_files = os.listdir(folder_path)

testdf = pd.read_csv("2024Combine.csv")
testqb = testdf[testdf['Pos'] == 'QB'].reset_index(drop=True)
testnameqb = testqb
testqb = testqb.iloc[:, 7:12]
testqb.drop(columns=['Bench'], inplace=True)
testqb.fillna(testqb.mean(), inplace=True)

testwr = testdf[testdf['Pos'] == 'WR'].reset_index(drop=True)
testnamewr = testwr
testwr = testwr.iloc[:, 6:12]
#test.drop(columns=['Bench'], inplace=True)
testwr.fillna(testwr.mean(), inplace=True)

# Filter out non-CSV files
csv_files = [f for f in all_files if f.endswith('.csv') and f != "combined_file.csv" and f != "2024Combine.csv"]

# Create a list to hold the dataframes
df_list = []

for csv in csv_files:
    file_path = os.path.join(folder_path, csv)
    try:
        # Try reading the file using default UTF-8 encoding
        df = pd.read_csv(file_path)
        df_list.append(df)
    except UnicodeDecodeError:
        try:
            # If UTF-8 fails, try reading the file using UTF-16 encoding with tab separator
            df = pd.read_csv(file_path, sep='\t', encoding='utf-16')
            df_list.append(df)
        except Exception as e:
            print(f"Could not read file {csv} because of error: {e}")
    except Exception as e:
        print(f"Could not read file {csv} because of error: {e}")

# Concatenate all data into one DataFrame
combdata = pd.concat(df_list, ignore_index=True)

# Save the final result to a new CSV file
combdata.to_csv(os.path.join(folder_path, 'combined_file.csv'), index=False)

#df = pd.DataFrame(combdata)

dfqb = combdata[combdata['Pos'] == 'QB'].reset_index(drop=True)
dfqb.insert(13,"Success",0)

print(dfqb)

dfwr = combdata[combdata['Pos'] == 'WR'].reset_index(drop=True)
dfwr.insert(13,"Success",0)

print(dfwr)


proQB = ["Patrick Mahomes", "Deshaun Watson", "Baker Mayfield", "Josh Allen", "Lamar Jackson", "Kyler Murray", "Joe Burrow", "Tua Tagovailoa", "Justin Herbert", "Jordan Love", "Jalen Hurts", "Trevor Lawrence","Brock Purdy", "C.J. Stroud", "Anthony Richardson"]
proWR = ["Noah Brown", "Chris Godwin", "Cooper Kupp", "JuJu Smith-Schuster", "Curtis Samuel", "Mike Williams", "Christian Kirk", "Courtland Sutton", "Calvin Ridley", "D.J. Moore", "Terry McLaurin", "D.K. Metcalf", "A.J. Brown", "Deebo Samuel", "Marquise Brown", "Michael Pittman", "Tee Higgins", "Brandon Aiyuk", "Justin Jefferson", "CeeDee Lamb", "Jerry Jeudy", "Amon-Ra St. Brown", "Nico Collins", "Ja'Marr Chase", "Romeo Doubs", "Christian Watson", "Chris Olave", "Garrett Wilson", "Drake London", "Puka Nacua", "Dontayvion Wicks", "Rashee Rice", "Jordan Addison", "Zay Flowers"]
#row_list= []


"""for QB in proQB:
# Iterate through each row of the original DataFrame
    row_index = dfqb[dfqb["Player"] == QB].index[0]

    dfqb.iloc[row_index, 13] = 1

dfqb.drop(columns=['Bench'], inplace=True)
#dfProQB = dfqb.iloc[row_list]
#dfProQB.insert(14,"Success")
X = dfqb.iloc[:, 7:11]  # Extract columns 7 through 12 as features
y = dfqb.iloc[:, 12]    # Extract column 13 as the target variable
"""
print(dfwr.head())

for WR in proWR:
# Iterate through each row of the original DataFrame
    row_index = dfwr[dfwr["Player"] == WR].index[0]

    dfwr.iloc[row_index, 13] = 1

#dfwr.drop(columns=['Bench'], inplace=True)
#dfProQB = dfqb.iloc[row_list]
#dfProQB.insert(14,"Success")

X = dfwr.iloc[:, 6:12]  # Extract columns 7 through 12 as features
print(dfwr.iloc[:, 6:12])
y = dfwr.iloc[:, 13]    # Extract column 13 as the target variable
print(dfwr.iloc[:,13])

X.fillna(X.mean(), inplace=True) #Handle NaN values

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Choose a classification model (e.g., logistic regression)
model = LogisticRegression()

# Train the model
model.fit(X_train_scaled, y_train)

# Evaluate the model
y_pred = model.predict_proba(X_test_scaled)
y_test_binary = (y_test > 0).astype(int)
print(classification_report(y_test_binary, np.argmax(y_pred, axis=1)))

# Predict success labels for new data
# Assuming new_data is a DataFrame with the same columns as X (columns 2 through 5)
new_data_scaled = scaler.transform(testwr)
probability_scores = model.predict_proba(new_data_scaled)

probability_success = probability_scores[:, 1]

# Add the probability scores to the DataFrame
testwr['Probability_Success'] = probability_success

# Filter the DataFrame to show only candidates predicted to have "success"
predicted_success_candidates = testwr[testwr['Probability_Success'] > 0.5]  # You can adjust the threshold as needed

# Display the predicted successful candidates

testwr = testwr.join(testnamewr["Player"])
print(testwr)